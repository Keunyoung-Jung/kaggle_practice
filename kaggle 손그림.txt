1. 문제 인식

문제에 제시된 설명을 읽고난 후 손그림을 분류 340개의 클래스로 훈련시켜 줘야한다는 것을 알았다.
평가 매기는 방식은 key_id테스트 세트에 대해 word값을 예측하는 것이고
word에 들어있는 공백은 '_'로 치환하여야 한다
데이터 탭으로 들어가 데이터에 대한 설명을 읽었다.
raw데이터와 simplified데이터가 있는데 모두 사용할수 있다고 했으나
simplified데이터가 동일안 정보를 효과적으로 제공한다고 써있어서 사용 (raw도들어갔으나 안들어가졌음)

2. 데이터 확인

pandas 모듈을 이용한 데이터 확인을 하였다.
먼저 csv를 읽어와서 문제에 제시된 word 열의 공백을 모두 '_'로 replace 해주었다.

3. 첫번째 난관

drawing이 이미지를 나타내는것은 알겠는데 pandas로 읽었기 때문에 모두 string으로 반환되었다
그래서 검색결과 np.matrix를 통해 변환할 수 있다는 것을 알았고 matrix를 사용하여
변환해 보았지만 가장안쪽 배열의 구조는 유지 되지 않은채 값들을 전부 1차원으로 반환하였다.
문자열이라 shape도 1차원으로 나오는 탓에 고민을 많이 했다.
구글링 검색결과 ast.literal_eval이라는 함수가 시퀀스형 데이터의 문자열을 변환할수있는걸 알았고
함수를 이용하여 변환해 주었다.

4. 두번째 난관

배열은 변환 하였으나 이미지가 내가 알던 형식이 아니었다. 처음엔 배열의 형태를 보고 당황
꽤나 오랫동안 고민하였다. 고민하면서 홈페이지의 문제를 다시 인식하기로 했고 dataset에 대한 깃허브페이지가 있었다.
깃허브 페이지를 보아 x,y,t로 이루어져있고 t에대한 정보를 제거해서 사용한다고 써있었는데
csv로 주어진 대회 데이터는 t는 이미 지워진 형태였다. bird[0]을 뽑으면 2가지의 배열만 있다.
그래서 t는 지워졌겠지하고 plt.plot을 이용하여 xy배열을 넣어 확인해보니 그림을 그릴 수 있었다.

5. 세번째 난관

그림은 그렸으나 이것을 이미지로 만들어야만 훈련데이터에 집어넣어 훈련을 해볼 수 있었는데 
plt에서 그린그림을 그대로 사용하기에는 PIL을 이용하여 이미지를 직접 그려넣어 주었다.
True data와 False data를 확인해보았는데 False는 그림이라고하기엔 애매한 것들이 들어있어
True data만 사용하기로 하였다.

6. 네번째 난관

전처리알고리즘을 끝내고 training data를 만드는데 1개의 클래스 (1개의 csv파일)당 약 1분30초가량걸렸다.
전체 데이터의 갯수가 약 3000만개 이므로 일단 훈련이 되고 accuracy확인하고 싶어서 클래스당 1000개의 데이터로
진행을 하였다.

7. 다섯번째 난관

CNN모델을 설계하여 바로 집어넣어 봤으나 전에 배웠던 1.9.0 버전이라 kaggle kernel에서 제공하는 tf버전은 2.0
이라서 문법이 안맞아 설계한게 무용지물됨 , keras모듈을 공부해서 다시 설계할 필요가 있음

8. keras공부 후

CNN 모델을 먼저 설계해서 넣어보았다 그러나 데이터의 양이 많아서 그런지 loss가 전혀 떨어 지지않았다.
VGG16 모델 또한 설계하여 넣어 보았는데 CNN 과 같은 결과를 얻었다
그후 ResNet을 설계한 것을 가져와서 넣었는데 작동이 되기 시작했다 그러나 22epoch기준으로 
acc가 훈련데이터는 평균 :0.7 최고 : 0.98 , 검증데이터는 평균 :0.5 최고 :0.83 에서 그쳤다.
epoch을 늘리기엔 훈련시간이 너무 길어서 클래스를 줄여서 전처리는 잘됬는지 구분을 잘하는지 먼저
알아보기로 하였다.

9. 실험 과정

3클래스 CNN은 loss가 떨어지지않아 acc도 오르지 않음 
	VGG16 도 CNN과 같은 결과
	ResNet은 50 epoch결과 val데이터를 0.97까지 구분해 냈다.

50클래스 CNN 위와 비슷한결과
	 VGG16 역시 비슷한결과
	 ResNet은 오르긴 하지만 일정구간에서 val데이터셋의 loss가 떨어지지 않고 acc가 정체

recognized 가True인 것으로 실험
recognized가 True인 경우 그림이 신뢰도가 높고 클래스를 나타내는 특징이 확실할것이라 생각하고 
recognized가 True인 것만 클래스에 포함시켜 훈련을 시켜보았다.

50클래스 CNN도 작동하기 시작했고 평균 acc가 83 , top acc가 95까지 줄었다. 훈련시간이 매우 적었다.
	 VGG는 역시 작동하지 않았음.
	 ResNet은 12epoch때 까지는 loss가 충분히 감소하고 평균 acc가 87 , 최고 acc가 98 까지 나왔다.
하지만 모든 모델들이 에포크 초반에 오버피팅이 되어 val loss가 발산을 하는 것을 확인할 수가 있었다.

50클래스 반전 이미지 CNN val loss 0.58 val acc 87  val_loss 0.5 acc 0.88  val_loss 0.49 acc 0.89


10. 마무리

ResNet은 성능이 나쁘지않게 나왔지만 그냥 짜여진 모델을 사용하는 것은 의미가 없다고 생각이 들었다.
그래서 그래프를 뽑아보며 오버피팅이 되더라도 최대한 loss가 발산하지 않게끔 만들어서 acc를 뽑아야 겠다고
생각이 들었다.
 
먼저 오버피팅을 막기위해 batch nomalization노드를 넣어 주고 실험을 다시했다. 그러나 아직도 오버피팅으로
loss가 발산해서 발산하는걸 막는걸 목표로 했다 dropout을 추가해서 다시 해보았더니 loss는 발산하지 않았지만
전체 acc가 높게 나오지 않았다. 그래서 데이터의 형태를 다시 보고 일정한패턴은 있지만 유일무이한 패턴이
없다고 생각하고 averagepooling을 사용해보았더니 acc가 향상 되었다.

340클래스 average -> val acc 75 top3 acc 91 Max -> val acc 69 top3 acc 89

직접 만든 모델로 제출파일까지 제작하여 끝을 냈다.
